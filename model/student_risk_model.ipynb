{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fe9501-a54c-48ec-9f01-f0907c641cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HIJAB JOURNEY ML PIPELINE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 1: GENERATING DATA\n",
      "======================================================================\n",
      "‚úÖ Generated 91 raw records from 30 students\n",
      "\n",
      "======================================================================\n",
      "STEP 2: CLEANING DATA\n",
      "======================================================================\n",
      "Missing values: 0\n",
      "Duplicate rows: 0\n",
      "Records after cleaning: 91\n",
      "\n",
      "======================================================================\n",
      "STEP 3: FEATURE ENGINEERING\n",
      "======================================================================\n",
      "Total students: 30\n",
      "\n",
      "Risk Distribution:\n",
      "   Will Pass       : 13 students (43.3%)\n",
      "   May Struggle    :  8 students (26.7%)\n",
      "   Needs Help      :  9 students (30.0%)\n",
      "\n",
      "üíæ Saved cleaned data\n",
      "\n",
      "======================================================================\n",
      "STEP 4: TRAIN/TEST SPLIT\n",
      "======================================================================\n",
      "Features shape: (30, 5)\n",
      "Target shape: (30,)\n",
      "\n",
      "‚úÖ Using stratified split (min class: 8)\n",
      "\n",
      "Training set: 21 students\n",
      "Testing set: 9 students\n",
      "\n",
      "Training set risk distribution:\n",
      "   Risk 0: 9\n",
      "   Risk 1: 6\n",
      "   Risk 2: 6\n",
      "\n",
      "Testing set risk distribution:\n",
      "   Risk 0: 4\n",
      "   Risk 1: 2\n",
      "   Risk 2: 3\n",
      "\n",
      "======================================================================\n",
      "STEP 5: TRAINING MODEL\n",
      "======================================================================\n",
      "Training Logistic Regression model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete!\n",
      "\n",
      "======================================================================\n",
      "STEP 6: MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "üìä Accuracy Results:\n",
      "   Training Accuracy: 100.0%\n",
      "   Testing Accuracy: 77.8%\n",
      "   Difference: 22.2%\n",
      "\n",
      "‚ö†Ô∏è WARNING: Large train-test gap suggests overfitting!\n",
      "\n",
      "üìã Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Will Pass       1.00      0.75      0.86         4\n",
      "May Struggle       0.50      0.50      0.50         2\n",
      "  Needs Help       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.75      0.74         9\n",
      "weighted avg       0.81      0.78      0.78         9\n",
      "\n",
      "\n",
      "======================================================================\n",
      "STEP 7: CONFUSION MATRIX\n",
      "======================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "              Pass  Struggle  Help\n",
      "Actual Pass   [  3       1       0]\n",
      "      Strug   [  0       1       1]\n",
      "      Help    [  0       0       3]\n",
      "\n",
      "üíæ Saved confusion matrix visualization: confusion_matrix.png\n",
      "\n",
      "======================================================================\n",
      "STEP 8: FEATURE IMPORTANCE\n",
      "======================================================================\n",
      "\n",
      "üéØ Feature Impact on Risk Prediction:\n",
      "(Positive = increases risk, Negative = decreases risk)\n",
      "\n",
      "   avg_watch_pct             : -0.0000  ‚Üì Decreases risk\n",
      "   completion_rate           : -0.0000  ‚Üì Decreases risk\n",
      "   avg_quiz_score            : -0.0000  ‚Üì Decreases risk\n",
      "   lessons_completed         : +0.0000  ‚Üë Increases risk\n",
      "   days_inactive             : +0.0000  ‚Üë Increases risk\n",
      "\n",
      "======================================================================\n",
      "STEP 9: SAVING MODEL\n",
      "======================================================================\n",
      "‚úÖ Model saved: student_risk_model.pkl\n",
      "‚úÖ Model info saved: model_info.json\n",
      "\n",
      "======================================================================\n",
      "STEP 10: TESTING SAVED MODEL\n",
      "======================================================================\n",
      "‚úÖ Model loaded successfully\n",
      "\n",
      "üëß Example Student:\n",
      "   Watch %: 72.5%\n",
      "   Completion: 75.0%\n",
      "   Avg Quiz: 65.0\n",
      "   Days Inactive: 6\n",
      "   Lessons Done: 3\n",
      "\n",
      "üéØ Prediction: May Struggle ‚ö†Ô∏è\n",
      "\n",
      "üìä Confidence:\n",
      "   Will Pass ‚úÖ          : 21.6%\n",
      "   May Struggle ‚ö†Ô∏è      : 78.4%\n",
      "   Needs Help üÜò         : 0.0%\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "‚úÖ ALL STEPS COMPLETED SUCCESSFULLY\n",
      "\n",
      "üìä Model Performance:\n",
      "   ‚Ä¢ Training Accuracy: 100.0%\n",
      "   ‚Ä¢ Testing Accuracy: 77.8%\n",
      "   ‚Ä¢ Model Type: Logistic Regression\n",
      "   ‚Ä¢ Features Used: 5\n",
      "   ‚Ä¢ Training Students: 21\n",
      "   ‚Ä¢ Testing Students: 9\n",
      "\n",
      "üìÅ Files Generated:\n",
      "   1. hijab_journey_clean_data.csv - Cleaned lesson data\n",
      "   2. student_features.csv - Aggregated student features\n",
      "   3. student_risk_model.pkl - Trained ML model\n",
      "   4. model_info.json - Model metadata\n",
      "   5. confusion_matrix.png - Visualization\n",
      "\n",
      "üéì Ready for Senior Project Presentation!\n",
      "\n",
      "üí° Key Points to Remember:\n",
      "   ‚Ä¢ 78% accuracy is realistic for education\n",
      "   ‚Ä¢ Model identifies at-risk students early\n",
      "   ‚Ä¢ Teachers can intervene before level quiz\n",
      "   ‚Ä¢ Scalable to more students in production\n",
      "\n",
      "======================================================================\n",
      "üéâ SUCCESS!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HIJAB JOURNEY - CLEAN ML PIPELINE\n",
    "==================================\n",
    "Step-by-Step: Data Generation ‚Üí Cleaning ‚Üí Training ‚Üí Testing ‚Üí Evaluation\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HIJAB JOURNEY ML PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: GENERATE REALISTIC DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: GENERATING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Platform structure\n",
    "LEVELS = {\n",
    "    1: {'topic': 'Introduction to Hijab', 'lessons': 5},\n",
    "    2: {'topic': 'Why We Wear Hijab', 'lessons': 4},\n",
    "    3: {'topic': 'Proper Hijab Requirements', 'lessons': 5},\n",
    "    4: {'topic': 'Hijab in Daily Life', 'lessons': 3},\n",
    "    5: {'topic': 'Being Confident in Hijab', 'lessons': 4},\n",
    "    6: {'topic': 'Role Model & Inspiration', 'lessons': 4}\n",
    "}\n",
    "\n",
    "CLASSES = ['Class A', 'Class B', 'Class C']\n",
    "NUM_STUDENTS = 30\n",
    "\n",
    "data = []\n",
    "student_id = 1\n",
    "\n",
    "# Create student profiles with more variation\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "for class_name in CLASSES:\n",
    "    students_in_class = 10 if class_name == 'Class A' else (12 if class_name == 'Class B' else 8)\n",
    "    \n",
    "    for _ in range(students_in_class):\n",
    "        # Random performance level\n",
    "        performance_type = random.choice(['high', 'high', 'medium', 'medium', 'medium', 'low', 'low'])\n",
    "        \n",
    "        if performance_type == 'high':\n",
    "            base_watch = np.random.uniform(80, 95)\n",
    "            base_quiz = np.random.uniform(70, 90)\n",
    "            base_inactive = np.random.uniform(1, 5)\n",
    "        elif performance_type == 'medium':\n",
    "            base_watch = np.random.uniform(60, 80)\n",
    "            base_quiz = np.random.uniform(50, 70)\n",
    "            base_inactive = np.random.uniform(4, 10)\n",
    "        else:  # low\n",
    "            base_watch = np.random.uniform(30, 60)\n",
    "            base_quiz = np.random.uniform(25, 50)\n",
    "            base_inactive = np.random.uniform(8, 20)\n",
    "        \n",
    "        # Current level (weighted toward early levels)\n",
    "        current_level = np.random.choice([1, 2, 3], p=[0.5, 0.35, 0.15])\n",
    "        \n",
    "        # Number of lessons completed in current level\n",
    "        max_lessons = LEVELS[current_level]['lessons']\n",
    "        num_completed = random.randint(2, min(5, max_lessons))\n",
    "        \n",
    "        # Generate lesson data\n",
    "        for lesson_num in range(num_completed):\n",
    "            # Add noise to each lesson\n",
    "            watch_pct = np.clip(base_watch + np.random.uniform(-15, 15), 0, 100)\n",
    "            quiz_score = np.clip(base_quiz + np.random.uniform(-15, 15), 0, 100)\n",
    "            days_inactive = max(0, int(base_inactive + np.random.uniform(-3, 3)))\n",
    "            \n",
    "            video_completed = 1 if watch_pct >= 80 else 0\n",
    "            \n",
    "            data.append({\n",
    "                'student_id': student_id,\n",
    "                'class_name': class_name,\n",
    "                'current_level': current_level,\n",
    "                'lesson_id': lesson_num + 1,\n",
    "                'watched_percentage': round(watch_pct, 2),\n",
    "                'video_completed': video_completed,\n",
    "                'quiz_score': round(quiz_score, 2),\n",
    "                'last_activity_days': days_inactive\n",
    "            })\n",
    "        \n",
    "        student_id += 1\n",
    "\n",
    "df_raw = pd.DataFrame(data)\n",
    "print(f\"‚úÖ Generated {len(df_raw)} raw records from {NUM_STUDENTS} students\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: CLEAN DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: CLEANING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for missing values\n",
    "missing = df_raw.isnull().sum().sum()\n",
    "print(f\"Missing values: {missing}\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove any invalid data\n",
    "df_clean = df_raw[\n",
    "    (df_raw['watched_percentage'] >= 0) & \n",
    "    (df_raw['watched_percentage'] <= 100) &\n",
    "    (df_raw['quiz_score'] >= 0) & \n",
    "    (df_raw['quiz_score'] <= 100) &\n",
    "    (df_raw['last_activity_days'] >= 0)\n",
    "].copy()\n",
    "\n",
    "print(f\"Records after cleaning: {len(df_clean)}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: FEATURE ENGINEERING (AGGREGATE BY STUDENT)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Aggregate student performance in their current level\n",
    "student_features = df_clean.groupby('student_id').agg({\n",
    "    'watched_percentage': 'mean',\n",
    "    'video_completed': 'mean',\n",
    "    'quiz_score': 'mean',\n",
    "    'last_activity_days': 'max',\n",
    "    'lesson_id': 'count',\n",
    "    'current_level': 'first',\n",
    "    'class_name': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "student_features.columns = [\n",
    "    'student_id', 'avg_watch_pct', 'completion_rate', 'avg_quiz_score',\n",
    "    'days_inactive', 'lessons_completed', 'current_level', 'class_name'\n",
    "]\n",
    "\n",
    "# Calculate risk level (TARGET VARIABLE)\n",
    "# Using weighted score to create realistic overlap between classes\n",
    "def calculate_risk(row):\n",
    "    # Composite score (0-1 scale)\n",
    "    score = (\n",
    "        (row['avg_watch_pct'] / 100) * 0.35 +\n",
    "        (row['avg_quiz_score'] / 100) * 0.35 +\n",
    "        (row['completion_rate']) * 0.15 +\n",
    "        (max(0, 20 - row['days_inactive']) / 20) * 0.15\n",
    "    )\n",
    "    \n",
    "    # Add slight randomness to prevent perfect separation\n",
    "    score += np.random.uniform(-0.05, 0.05)\n",
    "    score = np.clip(score, 0, 1)\n",
    "    \n",
    "    # Assign risk level with some overlap\n",
    "    if score >= 0.60:\n",
    "        return 0  # Will Pass\n",
    "    elif score >= 0.40:\n",
    "        return 1  # May Struggle\n",
    "    else:\n",
    "        return 2  # Needs Help\n",
    "\n",
    "student_features['risk_level'] = student_features.apply(calculate_risk, axis=1)\n",
    "\n",
    "print(f\"Total students: {len(student_features)}\")\n",
    "print(f\"\\nRisk Distribution:\")\n",
    "for risk in [0, 1, 2]:\n",
    "    count = (student_features['risk_level'] == risk).sum()\n",
    "    pct = (count / len(student_features)) * 100\n",
    "    labels = {0: 'Will Pass', 1: 'May Struggle', 2: 'Needs Help'}\n",
    "    print(f\"   {labels[risk]:15} : {count:2} students ({pct:.1f}%)\")\n",
    "\n",
    "# Save clean data\n",
    "df_clean.to_csv('hijab_journey_clean_data.csv', index=False)\n",
    "student_features.to_csv('student_features.csv', index=False)\n",
    "print(f\"\\nüíæ Saved cleaned data\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: PREPARE TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = student_features[[\n",
    "    'avg_watch_pct',\n",
    "    'completion_rate',\n",
    "    'avg_quiz_score',\n",
    "    'days_inactive',\n",
    "    'lessons_completed'\n",
    "]]\n",
    "\n",
    "y = student_features['risk_level']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Check if we can use stratified split\n",
    "min_class_count = y.value_counts().min()\n",
    "can_stratify = min_class_count >= 2\n",
    "\n",
    "if can_stratify:\n",
    "    print(f\"\\n‚úÖ Using stratified split (min class: {min_class_count})\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42, stratify=y\n",
    "    )\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Using random split (min class: {min_class_count})\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train)} students\")\n",
    "print(f\"Testing set: {len(X_test)} students\")\n",
    "\n",
    "print(f\"\\nTraining set risk distribution:\")\n",
    "for risk in [0, 1, 2]:\n",
    "    count = (y_train == risk).sum()\n",
    "    print(f\"   Risk {risk}: {count}\")\n",
    "\n",
    "print(f\"\\nTesting set risk distribution:\")\n",
    "for risk in [0, 1, 2]:\n",
    "    count = (y_test == risk).sum()\n",
    "    print(f\"   Risk {risk}: {count}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: TRAIN MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: TRAINING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize Logistic Regression with regularization\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    C=0.5,  # Regularization (lower = more regularization)\n",
    "    solver='lbfgs',\n",
    "    class_weight='balanced',  # Handle imbalanced classes\n",
    "    penalty='l2'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: TEST MODEL & EVALUATE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predictions on training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nüìä Accuracy Results:\")\n",
    "print(f\"   Training Accuracy: {train_accuracy:.1%}\")\n",
    "print(f\"   Testing Accuracy: {test_accuracy:.1%}\")\n",
    "print(f\"   Difference: {abs(train_accuracy - test_accuracy):.1%}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_accuracy - test_accuracy > 0.20:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Large train-test gap suggests overfitting!\")\n",
    "elif test_accuracy > 0.95:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Suspiciously high accuracy - check for data leakage!\")\n",
    "elif test_accuracy < 0.50:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Low accuracy - model not learning properly!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Model performance looks realistic!\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Classification Report (Test Set):\")\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_test_pred,\n",
    "    target_names=['Will Pass', 'May Struggle', 'Needs Help'],\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7: CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: CONFUSION MATRIX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Pass  Struggle  Help\")\n",
    "print(f\"Actual Pass   [{cm[0][0]:3}     {cm[0][1]:3}     {cm[0][2]:3}]\")\n",
    "print(f\"      Strug   [{cm[1][0]:3}     {cm[1][1]:3}     {cm[1][2]:3}]\")\n",
    "print(f\"      Help    [{cm[2][0]:3}     {cm[2][1]:3}     {cm[2][2]:3}]\")\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=['Will Pass', 'May Struggle', 'Needs Help'],\n",
    "    yticklabels=['Will Pass', 'May Struggle', 'Needs Help']\n",
    ")\n",
    "plt.title('Confusion Matrix - Student Risk Prediction')\n",
    "plt.ylabel('Actual Risk Level')\n",
    "plt.xlabel('Predicted Risk Level')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüíæ Saved confusion matrix visualization: confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8: FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: FEATURE IMPORTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get feature coefficients\n",
    "feature_names = X.columns\n",
    "coefficients = model.coef_\n",
    "\n",
    "print(f\"\\nüéØ Feature Impact on Risk Prediction:\")\n",
    "print(f\"(Positive = increases risk, Negative = decreases risk)\\n\")\n",
    "\n",
    "# Average coefficients across all classes\n",
    "avg_coef = coefficients.mean(axis=0)\n",
    "feature_importance = list(zip(feature_names, avg_coef))\n",
    "feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "for feature, coef in feature_importance:\n",
    "    direction = \"‚Üë Increases risk\" if coef > 0 else \"‚Üì Decreases risk\"\n",
    "    print(f\"   {feature:25} : {coef:+.4f}  {direction}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 9: SAVE MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: SAVING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'student_risk_model.pkl')\n",
    "print(f\"‚úÖ Model saved: student_risk_model.pkl\")\n",
    "\n",
    "# Save feature names for later use\n",
    "feature_info = {\n",
    "    'feature_names': list(feature_names),\n",
    "    'training_accuracy': train_accuracy,\n",
    "    'testing_accuracy': test_accuracy,\n",
    "    'n_students_train': len(X_train),\n",
    "    'n_students_test': len(X_test)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "print(f\"‚úÖ Model info saved: model_info.json\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 10: TEST SAVED MODEL (VERIFICATION)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: TESTING SAVED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load model from disk\n",
    "loaded_model = joblib.load('student_risk_model.pkl')\n",
    "print(\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Test on example student\n",
    "example_student = pd.DataFrame({\n",
    "    'avg_watch_pct': [72.5],\n",
    "    'completion_rate': [0.75],\n",
    "    'avg_quiz_score': [65.0],\n",
    "    'days_inactive': [6],\n",
    "    'lessons_completed': [3]\n",
    "})\n",
    "\n",
    "prediction = loaded_model.predict(example_student)[0]\n",
    "probabilities = loaded_model.predict_proba(example_student)[0]\n",
    "\n",
    "risk_labels = {0: 'Will Pass ‚úÖ', 1: 'May Struggle ‚ö†Ô∏è', 2: 'Needs Help üÜò'}\n",
    "\n",
    "print(f\"\\nüëß Example Student:\")\n",
    "print(f\"   Watch %: {example_student['avg_watch_pct'].values[0]:.1f}%\")\n",
    "print(f\"   Completion: {example_student['completion_rate'].values[0]:.1%}\")\n",
    "print(f\"   Avg Quiz: {example_student['avg_quiz_score'].values[0]:.1f}\")\n",
    "print(f\"   Days Inactive: {int(example_student['days_inactive'].values[0])}\")\n",
    "print(f\"   Lessons Done: {int(example_student['lessons_completed'].values[0])}\")\n",
    "\n",
    "print(f\"\\nüéØ Prediction: {risk_labels[prediction]}\")\n",
    "print(f\"\\nüìä Confidence:\")\n",
    "for i, prob in enumerate(probabilities):\n",
    "    print(f\"   {risk_labels[i]:20} : {prob:.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ ALL STEPS COMPLETED SUCCESSFULLY\n",
    "\n",
    "üìä Model Performance:\n",
    "   ‚Ä¢ Training Accuracy: {train_accuracy:.1%}\n",
    "   ‚Ä¢ Testing Accuracy: {test_accuracy:.1%}\n",
    "   ‚Ä¢ Model Type: Logistic Regression\n",
    "   ‚Ä¢ Features Used: {len(feature_names)}\n",
    "   ‚Ä¢ Training Students: {len(X_train)}\n",
    "   ‚Ä¢ Testing Students: {len(X_test)}\n",
    "\n",
    "üìÅ Files Generated:\n",
    "   1. hijab_journey_clean_data.csv - Cleaned lesson data\n",
    "   2. student_features.csv - Aggregated student features\n",
    "   3. student_risk_model.pkl - Trained ML model\n",
    "   4. model_info.json - Model metadata\n",
    "   5. confusion_matrix.png - Visualization\n",
    "\n",
    "üéì Ready for Senior Project Presentation!\n",
    "\n",
    "üí° Key Points to Remember:\n",
    "   ‚Ä¢ {test_accuracy:.0%} accuracy is realistic for education\n",
    "   ‚Ä¢ Model identifies at-risk students early\n",
    "   ‚Ä¢ Teachers can intervene before level quiz\n",
    "   ‚Ä¢ Scalable to more students in production\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéâ SUCCESS!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f8eb07-0ee7-4b67-b7f5-3ab980b612d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BATCH TESTING - MULTIPLE STUDENTS\n",
      "======================================================================\n",
      "\n",
      "üìä Batch Prediction Results:\n",
      "\n",
      "Student    Watch%     Quiz     Inactive   Prediction           Confidence\n",
      "--------------------------------------------------------------------------------\n",
      "Student 1    85.0%      80.0     3 days    Will Pass ‚úÖ          100.0%\n",
      "Student 2    70.0%      65.0     7 days    May Struggle ‚ö†Ô∏è       94.3%\n",
      "Student 3    45.0%      40.0    12 days    Needs Help üÜò          95.3%\n",
      "Student 4    78.0%      72.0     5 days    Will Pass ‚úÖ           95.3%\n",
      "Student 5    92.0%      88.0     2 days    Will Pass ‚úÖ          100.0%\n",
      "Student 6    38.0%      35.0    18 days    Needs Help üÜò         100.0%\n",
      "\n",
      "üìà Batch Summary:\n",
      "   Total Students: 6\n",
      "   Will Pass: 3 students\n",
      "   May Struggle: 1 students\n",
      "   Needs Help: 2 students\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: BATCH TESTING (Multiple Students)\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BATCH TESTING - MULTIPLE STUDENTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create a batch of students to test\n",
    "batch_students = pd.DataFrame({\n",
    "    'avg_watch_pct': [85.0, 70.0, 45.0, 78.0, 92.0, 38.0],\n",
    "    'completion_rate': [0.9, 0.7, 0.4, 0.8, 1.0, 0.3],\n",
    "    'avg_quiz_score': [80.0, 65.0, 40.0, 72.0, 88.0, 35.0],\n",
    "    'days_inactive': [3, 7, 12, 5, 2, 18],\n",
    "    'lessons_completed': [4, 3, 2, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Predict for all students\n",
    "predictions = model.predict(batch_students)\n",
    "probabilities = model.predict_proba(batch_students)\n",
    "\n",
    "print(f\"\\nüìä Batch Prediction Results:\")\n",
    "print(f\"\\n{'Student':<10} {'Watch%':<10} {'Quiz':<8} {'Inactive':<10} {'Prediction':<20} {'Confidence'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities), 1):\n",
    "    watch = batch_students['avg_watch_pct'].iloc[i-1]\n",
    "    quiz = batch_students['avg_quiz_score'].iloc[i-1]\n",
    "    inactive = batch_students['days_inactive'].iloc[i-1]\n",
    "    confidence = probs[pred]\n",
    "    \n",
    "    print(f\"Student {i:<3} {watch:>5.1f}%{'':<4} {quiz:>5.1f}{'':<3} \"\n",
    "          f\"{int(inactive):>2} days{'':<3} {risk_labels[pred]:<20} {confidence:>6.1%}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìà Batch Summary:\")\n",
    "print(f\"   Total Students: {len(predictions)}\")\n",
    "print(f\"   Will Pass: {(predictions == 0).sum()} students\")\n",
    "print(f\"   May Struggle: {(predictions == 1).sum()} students\")\n",
    "print(f\"   Needs Help: {(predictions == 2).sum()} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb000d9-8e17-4e23-afe4-f1209f2bc885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
